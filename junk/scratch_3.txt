Nonlinear without nonlinear regularization
Add unit test for different modes of opperation
Add all options

func v grad shared computation
base class
intr(self, X)
func(self, X, I=None, full_output=False)
grad(self, X, I=None, full_output=False)
_intr(self, X)
_func(self, X, I)
_grad(self, X, I)


n_components=None,
kernel='linear' | 'linear', 'rbf'
regularization='auto' | 'auto', 'unweighted'
init='pca' | 'random', 'zero', 'identity', 'centered', 'pca'
max_iter=50
tol=1e-05
callback=None | f(MLNNEngine, MLNNOptimizer, iter)
verbose=0 | 0, 1, 2
random_state=None
solver='steepest_fixed_backtracking' | 'steepest'/'bfgs', 'fixed'/'alternating', 'backtracking'/'strong_wolfe'
A_0=None
E_0=None

collect_stats=False
animate=False
backend='numpy' | 'numpy', 'jax', 'cupy', 'numba'

self.mlnn_params
    'r': 1
    's': 0
    'l': 1
    'q': 1
    'inner_loss': loss
    'outer_loss': loss
    'a_mode': 'decomposed',
    'e_mode': 'single',
    'keep_a_psd': False,
    'keep_a_centered': False,
    'keep_e_positive': False,

self.optimize_params
    'max_time': np.inf,
    'fixed_arguments': 'AE',
    'max_arg_steps': 5,
    'maxcor': None,
    'gtol': None,
    'eps': None,
    'maxfun': None,
    'finite_diff_rel_step': None,


self.line_search_params
    'max_ls_iterations': 20,
    'use_prev_f': False,
    'alpha_0': 1e-3,
    'armijo': 1e-06,
    'wolfe': 0.9,
    'rho_lo': 0.1,
    'rho_hi': 0.9,

